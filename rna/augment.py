"""
Both functions to augment data and to manipulate augmented data.
"""

import numpy as np

from rna.analytics import combine_samples


def construct_random_samples(X, y, n, classes_to_include, n_features, binarize):
    """
    Returns n generated samples that contain classes classes_to_include.
    A sample is generated by random sampling a sample for each class, and adding
    the shuffled replicates.

    :param binarize:
    :param X: N_single_cell_experimental_samples array and within a list filled with
        for each n_single_cell_experimental_sample a N_measurements per sample x N_markers array
    :param y: list of length N_single_cell_experimental_samples filled with int labels of which
        cell type was measured
    :param n: number of samples to generate
    :param classes_to_include: iterable of int, cell type indices to include
        in the mixtures
    :param n_features: int N_markers (=N_features)
    :return: n x n_features array
    """
    if len(classes_to_include) == 0:
        return np.zeros((n, n_features))
    data_for_class=[]
    for clas in classes_to_include:
        data_for_class.append(X[np.argwhere(np.array(y) == clas)[:, 0]])

    augmented_samples = []
    for i in range(n):
        sampled = []
        for j, clas in enumerate(classes_to_include):

            n_in_class = sum(np.array(y) == clas)
            sampled_sample = data_for_class[j][np.random.randint(n_in_class)]
            n_replicates = len(sampled_sample)
            sampled.append(sampled_sample[np.random.permutation(n_replicates)])
        # TODO thus lower replicates for more cell types. is this an issue?
        smallest_replicates = min([len(sample) for sample in sampled])

        combined_sample = []
        for i_replicate in range(smallest_replicates):
            # TODO: Best way to combine the samples?
            combined_sample.append(np.max(np.array([sample[i_replicate] for sample in sampled]), axis=0))
            # combined_sample.append(np.mean(np.array([sample[i_replicate] for sample in sampled]), axis=0))
            # combined_sample.append(np.sum(np.array([sample[i_replicate] for sample in sampled]), axis=0))

        augmented_samples.append(combined_sample)

    if binarize:
        augmented_samples_bin = [
            [np.where(augmented_samples[i][j] > 150, 1, 0) for j in range(len(augmented_samples[i]))] for i in
            range(len(augmented_samples))]
        combined_samples = combine_samples(np.array(augmented_samples_bin))
    else:
        combined_samples = combine_samples(np.array(augmented_samples))

    return combined_samples


def augment_data(X, y, n_celltypes, n_features, N_SAMPLES_PER_COMBINATION, label_encoder, priors=None, binarize=False,
                 from_penile=False):
    """
    Generate data for the power set of single cell types

    :param priors:
    :param X: n_samples x n_measurements per sample x n_markers array of measurements
    :param y_nhot: n_samples x n_celltypes_with_penile array of int labels of which
        cell type was measured
    :param n_celltypes: int: number of single cell types
    :param n_features: int: n_markers
    :param N_SAMPLES_PER_COMBINATION:
    :param label_encoder:
    :param from_penile: bool: generate sample that (T) always or (F) never
        also contain penile skin
    :return: n_experiments x n_markers array,
             n_experiments x n_celltypes matrix of 0, 1 indicating for each augmented sample
                which single cell type it was made up of. Does not contain column for penile skin
    """

    if priors is None: # uniform priors
        priors = [1] * n_celltypes

    assert len(priors) == n_celltypes, "Not all cell types are given a prior value"

    if len(np.unique(priors)) == 1:
        ratio_relevant_prior = 0.5
        ratio_other_priors = 0.5
    # !only works with two unique priors values!
    else:
        counts = {priors.count(value): value for value in list(set(priors))}
        value_relevant_prior = counts[1]
        ratio_relevant_prior = (value_relevant_prior - 1) / value_relevant_prior
        index_of_relevant_prior = priors.index(value_relevant_prior)

        counts.pop(1)
        value_other_priors = list(counts.values())[0]
        ratio_other_priors = 1-ratio_relevant_prior


    if X.size == 0:
        # This is the case when calibration_size = 0.0, this is an implicit way to
        # ensure that calibration is not performed.
        X_augmented=None
        y_nhot_augmented=np.zeros((0, n_celltypes))

    else:
        X_augmented = np.zeros((0, n_features))
        N_SAMPLES = int(2 * N_SAMPLES_PER_COMBINATION * ratio_relevant_prior * (2 ** (n_celltypes-1)) + \
                    2 * N_SAMPLES_PER_COMBINATION * ratio_other_priors * 2 ** ((n_celltypes-1)))
        assert N_SAMPLES == N_SAMPLES_PER_COMBINATION * 2 ** n_celltypes
        # N_SAMPLES = np.sum(np.unique(priors) * N_SAMPLES_PER_COMBINATION * 2 ** n_celltypes * (1 / len(np.unique(priors))), dtype=int)
        y_nhot_augmented = np.zeros((N_SAMPLES, n_celltypes), dtype=int)

        begin = 0
        for i in range(2 ** n_celltypes):
            binary = bin(i)[2:]
            while len(binary) < n_celltypes:
                binary = '0' + binary

            # figure out which classes will be in the combination each iteration
            classes_in_current_mixture = []
            for i_celltype in range(len(label_encoder.classes_)):
                if binary[-i_celltype - 1] == '1':
                    classes_in_current_mixture.append(i_celltype)
            if from_penile:
                # also (always) add penile skin samples. the index for penile is n_celltypes
                classes_in_current_mixture.append(n_celltypes)

            # if the cell type is in the classes_in_current_mixture
            try:
                if index_of_relevant_prior in classes_in_current_mixture:
                    Np = value_relevant_prior * ratio_relevant_prior
                else:
                    Np = value_other_priors * ratio_other_priors
            except: # in the uniform case
                Np = 1

            end = begin + N_SAMPLES_PER_COMBINATION * Np
            for i_celltype in range(len(label_encoder.classes_)):
                if binary[-i_celltype - 1] == '1':
                    y_nhot_augmented[begin:end, i_celltype] = 1
            if from_penile:
                y_nhot_augmented[begin:end, n_celltypes] = 1

            X_augmented = np.append(X_augmented,
                                    construct_random_samples(X, y, end - begin, classes_in_current_mixture, n_features,
                                                             binarize=binarize), axis=0)
            begin = end

        if not binarize:
            X_augmented = X_augmented / 1000

    return X_augmented, y_nhot_augmented[:, :n_celltypes]


class MultiLabelEncoder():

    def __init__(self, n_classes):
        self.n_classes = n_classes
        self.nhot_of_combinations = make_nhot_matrix_of_combinations(n_classes)

    def nhot_to_labels(self, y_nhot):
        y = np.array([np.argwhere(np.all(self.nhot_of_combinations == y_nhot[i, :], axis=1)).flatten() for i in range(y_nhot.shape[0])])
        return y.ravel()

    def labels_to_nhot(self, y):
        if len(y.shape) == 1 or y.shape[1] == 1:
            n = y.shape[0]
            # TODO: FutureWarning: arrays to stack must be passed as a "sequence" ...
            y_nhot = np.vstack(self.nhot_of_combinations[y[i], :] for i in range(n))
        return y_nhot

    def transform_single(self, y):
        """
        Transforms the MultiLabelEncoded labels into original labels
        """
        y = y.reshape(-1, 1)
        y_transformed = np.zeros_like(y)
        for label in np.unique(y):
            y_transformed[np.argwhere(np.all(y == label, axis=1)).flatten()] = np.log2(label)

        return y_transformed

    def inv_transform_single(self, y):
        """
        Transforms the original labels into the MultiLabelEncoded labels
        """
        y_transformed = np.zeros_like(y)
        for label in np.unique(y):
            y_transformed[np.argwhere(np.all(y == label, axis=1)).flatten()] = 2 ** label

        return y_transformed


def make_nhot_matrix_of_combinations(N):
    """
    Makes nhot encoded matrix with all possible combinations of existing
    single cell types.

    :param N: int
    :return: 2**N x N nhot encoded matrix
    """

    def int_to_binary(i):
        binary = bin(i)[2:]
        while len(binary) < N:
            binary = '0' + binary
        return np.flip([int(j) for j in binary]).tolist()

    return np.array([int_to_binary(i) for i in range(2**N)])


def only_use_same_combinations_as_in_mixtures(X_augmented, y_nhot, y_nhot_mixtures):
    """
    Make sure that the combinations of cell types present in the mixtures dataset is the
    same in the augmented test dataset.
    """

    unique_mixture_combinations = np.unique(y_nhot_mixtures, axis=0)
    indices = [np.argwhere(np.all(y_nhot == unique_mixture_combinations[i, :], axis=1)).tolist() for i in range(unique_mixture_combinations.shape[0])]
    indices_flatter = [val for sublist in indices for val in sublist]
    indices_flattened = [val for sublist in indices_flatter for val in sublist]

    X_reduced = X_augmented[indices_flattened, :]
    y_nhot_reduced = y_nhot[indices_flattened, :]

    return X_reduced, y_nhot_reduced